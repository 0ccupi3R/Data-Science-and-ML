{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne <br>\n",
    "Author Blog: https://www.securitynik.com <br>\n",
    "Author GitHub:github.com/securitynik <br>\n",
    "Author Books: [  <br>\n",
    "                \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\",  <br>\n",
    "                \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\" <br>\n",
    "            ] <br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Beginning Deep Learning, - Classification, Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is part of my beginning machine learning series.  <br>\n",
    "The series includes the following: <br>\n",
    "\n",
    "01 - Beginning Numpy <br>\n",
    "02 - Beginning Tensorflow  <br>\n",
    "03 - Beginning PyTorch <br>\n",
    "04 - Beginning Pandas <br>\n",
    "05 - Beginning Matplotlib <br>\n",
    "06 - Beginning Data Scaling <br>\n",
    "07 - Beginning Principal Component Analysis (PCA) <br>\n",
    "08 - Beginning Machine Learning Anomaly Detection - Isolation Forest and Local Outlier Factor <br>\n",
    "09 - Beginning Unsupervised Machine Learning - Clustering - K-means and DBSCAN <br>\n",
    "10 - Beginning Supervise Learning - Machine Learning - Logistic Regression, Decision Trees and Metrics <br>\n",
    "11 - Beginning Linear Regression - Machine Learning <br>\n",
    "12 - Beginning Deep Learning - Anomaly Detection with AutoEncoders, Tensorflow <br>\n",
    "13 - Beginning Deep Learning - Anomaly Detection with AutoEncoders, PyTroch <br>\n",
    "14 - Beginning Deep Learning, - Linear Regression, Tensorflow <br>\n",
    "15 - Beginning Deep Learning, - Linear Regression, PyTorch <br>\n",
    "16 - Beginning Deep Learning, - Classification, Tensorflow <br>\n",
    "17 - Beginning Deep Learning, - Classification, Pytorch <br>\n",
    "18 - Beginning Deep Learning, - Classification - regression - MIMO - Functional API Tensorflow <br> \n",
    "19 - Beginning Deep Learning, - Convolution Networks - Tensorflow <br>\n",
    "20 - Beginning Deep Learning, - Convolution Networks - PyTorch <br>\n",
    "21 - Beginning Regularization - Early Stopping, Dropout, L2 (Ridge), L1 (Lasso) <br>\n",
    "23 - Beginning Model TFServing <br>\n",
    "\n",
    "But conn.log is not the only file within Zeek. Let's build some models for DNS and HTTP logs. <br>\n",
    "I choose unsupervised, because there are no labels coming with these data. <br>\n",
    "\n",
    "24 - Continuing Anomaly Learning - Zeek DNS Log - Machine Learning <br>\n",
    "25 - Continuing Unsupervised Learning - Zeek HTTP Log - Machine Learning <br>\n",
    "\n",
    "This was a specific ask by someone in one of my class. <br>\n",
    "26 - Beginning - Reading Executables and Building a Neural Network to make predictions on suspicious vs suspicious  <br><br>\n",
    "\n",
    "With 26 notebooks in this series, it is quite possible there are things I could have or should have done differently.  <br>\n",
    "If you find any thing, you think fits those criteria, drop me a line. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the notebooks on Pandas, Matplotlib and Scaling\n",
    "#   04 - Beginning Pandas <br>\n",
    "# we loaded our dataset such as\n",
    "df_conn = pd.read_csv(r'df_conn_with_labels.csv', index_col=0)\n",
    "df_conn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file represents Zeek (formerly Bro) connection log - conn.log`. \n",
    "Zeek is a framework used for Network Security Monitoring. \n",
    "This entire series is based on using Zeek's data. \n",
    "The majority of the notebooks use the conn.log\n",
    "You can learn more about Zeek here:\n",
    "   \n",
    "    https://zeek.org/\n",
    "\n",
    "Alternatively, come hang out with us in the:\n",
    "SANS SEC595: Applied Data Science and Machine Learning for Cybersecurity Professionals\n",
    "\n",
    "        https://www.sans.org/cyber-security-courses/applied-data-science-machine-learning/ OR\n",
    "\n",
    "SEC503 SEC503: Network Monitoring and Threat Detection In-Depth\n",
    "\n",
    "        https://www.sans.org/cyber-security-courses/network-monitoring-threat-detection/\n",
    "\n",
    "\n",
    "Here are also some blog posts on using Zeek for security monitoring\n",
    "Installing Zeek: \n",
    "\n",
    "        https://www.securitynik.com/2020/06/installing-zeek-314-on-ubuntu-2004.html\n",
    "\n",
    "Detecting PowerShell Empire Usage: \n",
    "\n",
    "        https://www.securitynik.com/2022/02/powershell-empire-detection-with-zeek.html\n",
    "\n",
    "Detecting Log4J Vulnerability Exploitation: \n",
    "\n",
    "        https://www.securitynik.com/2021/12/continuing-log4shell-zeek-detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the port column\n",
    "df_conn = df_conn.drop(columns=['id.resp_p'], inplace=False)\n",
    "df_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at above, we see a number of records with 0s. \n",
    "# These will add no value to our learning process\n",
    "# Let's find all those records and drop them\n",
    "# Reference: https://stackoverflow.com/questions/13851535/how-to-delete-rows-from-a-pandas-dataframe-based-on-a-conditional-expression\n",
    "df_conn = df_conn.drop(df_conn[(df_conn.duration == 0 ) & (df_conn.orig_bytes == 0 ) \\\n",
    "                               & (df_conn.resp_bytes == 0 ) & (df_conn.orig_pkts == 0 )  \\\n",
    "                                & (df_conn.orig_ip_bytes == 0 ) & (df_conn.resp_pkts == 0 ) \\\n",
    "                                    & (df_conn.resp_ip_bytes == 0 )].index)\n",
    "df_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph below shows this dataset is highly imbalanced.\n",
    "# As a result, using measures like accuracy is more than likely not the best approach, \n",
    "# to understand how well our eventual model has \"learned\"\n",
    "# via the training data\n",
    "plt.title('Bar graph showing highly imbalanced dataset')\n",
    "plt.bar(x=['normal', 'suspicious'], height=[ df_conn[df_conn.label == 0].shape[0], \\\n",
    "                                            df_conn[df_conn.label == 1].shape[0] ])\n",
    "plt.ylabel(ylabel='Number of Records')\n",
    "plt.xlabel(xlabel='Normal vs Suspicious')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the percentage of samples that are considered suspicious in this dataset\n",
    "# This is going to be quite a challenge for this learning algorithm\n",
    "(df_conn[df_conn.label == 1].shape[0] / df_conn.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the X_data\n",
    "X_data = df_conn.drop(columns=['label'], inplace=False)\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels\n",
    "y_label = df_conn.label\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data.values, y_label, test_size=0.2, \\\n",
    "                                                    train_size=0.8, stratify=y_label, random_state=10)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a statistical understanding of the normal and suspicious datasets, time to build the model\n",
    "# Scaling was covered in \n",
    "#   06 - Beginning Data Scaling\n",
    "# Scaling the data first\n",
    "# import the scaler library\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the scaler\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Fit on the training data\n",
    "min_max_scaler.fit(X_train)\n",
    "\n",
    "# Transform the train data\n",
    "X_train = min_max_scaler.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the test data\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA to leverage dimensionality reduction\n",
    "# PCA was covered in notebook\n",
    "#   07 - Beginning Principal Component Analysis (PCA)\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup PCA to use 3 principal Components\n",
    "pca = PCA(n_components=3, random_state=10)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on the X_train\n",
    "pca.fit(X_train)\n",
    "\n",
    "# transform the training data\n",
    "X_train = pca.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the opportunity to PCA transform the X_test\n",
    "X_test = pca.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Import the torchinfo to get summary information\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the train and test data from numpy arrays to tensors\n",
    "X_train, X_test = torch.tensor(data=X_train, dtype=torch.float32), torch.tensor(data=X_test, dtype=torch.float32)\n",
    "\n",
    "# Get a snapshot of the data\n",
    "X_train[:5], X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the panda series to a numpy array\n",
    "# Make the array 2 dimensions\n",
    "# Reshape to have multiple rows and 1 column\n",
    "y_train = np.array(y_train.values, ndmin=2, dtype=np.float32).reshape(-1, 1)\n",
    "y_test = np.array(y_test.values, ndmin=2, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "# Get 5 samples from each\n",
    "y_train[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to torch tensor\n",
    "y_train = torch.tensor(data=y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(data=y_test, dtype=torch.float32)\n",
    "\n",
    "y_train[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model using the Sequential Class\n",
    "torch_clf_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=3, out_features=8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=8, out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summary of the model\n",
    "torchinfo.summary(torch_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to visualize the model\n",
    "# https://github.com/mert-kurttutan/torchview\n",
    "from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "# https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch\n",
    "model_graph = draw_graph(model=torch_clf_model, input_data=X_train, graph_name='torch_clf_model', \\\n",
    "                         expand_nested=True, save_graph=False,show_shapes=True, graph_dir='RL', \\\n",
    "                            roll=True, hide_inner_tensors=False, hide_module_functions=False)\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a look at the initialized parameters - weights and bias\n",
    "torch_clf_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training the model, let's see what ReLU does\n",
    "# Setup some samples between -10 and 10, space them by 0.1\n",
    "sample_numbers = np.arange(-10, 10, 0.1)\n",
    "np.round(sample_numbers[95:106], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the numbers that were created above\n",
    "# we see there are 200 numbers between -10 and 10\n",
    "plt.title('Range of values between -10 and +10')\n",
    "plt.plot(sample_numbers)\n",
    "plt.xlabel('Number of records')\n",
    "plt.ylabel('Range of Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Relu, anything less than 0 will be made 0 and anything above 0 will be kept the same\n",
    "# Setup a function to take care of this \n",
    "def my_relu(x: np.array) -> list:\n",
    "    ''' Computes  RELU from the x '''\n",
    "    return [ 0 if i <=0 else i for i in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our function with 2 values\n",
    "# One less than 0 and another greater than 0\n",
    "# We see below when x is less than 0, the value returned is 0\n",
    "my_relu(np.array([-10])), my_relu(np.array([10])), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Relu against our relu_samples\n",
    "my_relu(sample_numbers)[96:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making this more visual by plotting the original numbers vs the numbers which RELU has been applied to\n",
    "# As we can see, anything below 0 has now become 0\n",
    "plt.plot(sample_numbers, lw=10, label='original values')\n",
    "plt.plot(my_relu(sample_numbers), lw=2, linestyle='--', label='values after RELU activation')\n",
    "plt.xlabel('Number of records')\n",
    "plt.ylabel('Range of Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following notebooks:\n",
    "#   13. Beginning Deep Learning - Anomaly Detection with AutoEncoders, PyTroch\n",
    "#   15. Beginning Deep Learning, - Linear Regression, PyTorch\n",
    "# the training was all done outside of a function. \n",
    "# Rather than rewriting the same code all the time, let's to create a function\n",
    "def torch_training(model=None, epochs=10, learning_rate=0.01, x_train=X_train, \\\n",
    "                   y_train=y_train, x_test=X_test, y_test=y_test):\n",
    "    ''' Performs training of the model '''\n",
    "    # Create to lists to save the training and test loss respectively \n",
    "    training_loss, validation_loss = [], []\n",
    "\n",
    "    # Setup the loss function\n",
    "    clf_loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "    # Setup the optimizer\n",
    "    clf_optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Clear the gradients\n",
    "        clf_optimizer.zero_grad()\n",
    "\n",
    "        # Train the model\n",
    "        model.train()\n",
    "\n",
    "        # Make predictions on the training data\n",
    "        train_preds = model(x_train)\n",
    "    \n",
    "        # Get the loss\n",
    "        train_loss = clf_loss_fn(train_preds, y_train)\n",
    "        training_loss.append(train_loss)\n",
    "\n",
    "        # Calculate the gradients\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Upgrade the gradients\n",
    "        clf_optimizer.step()\n",
    "\n",
    "        # Evaluate the model at the same time\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            val_preds = model(X_test)\n",
    "\n",
    "            # Calculate the loss on the validation data\n",
    "            val_loss = clf_loss_fn(val_preds, y_test)\n",
    "            validation_loss.append(val_loss)\n",
    "\n",
    "        if epoch %50 == 0:\n",
    "            print(f'Epoch: {epoch} \\t training loss: {train_loss} \\t validation loss {val_loss}')\n",
    "    \n",
    "    return model, training_loss, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed to make this repatable\n",
    "torch.manual_seed(seed=10)\n",
    "\n",
    "# Call the function with the associated parameters\n",
    "#(model, train_loss, val_loss) = torch_training(model=torch_clf_model, epochs=300, learning_rate=0.01)\n",
    "torch_clf_model = torch_training(model=torch_clf_model, epochs=300, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What has the model returned?\n",
    "torch_clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model Learned parameters - Weights and Bias\n",
    "torch_clf_model[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training loss values\n",
    "plt.title(f'Training vs Validation Loss after epochs ')\n",
    "\n",
    "# Trying to plot on the \"training_loss\" by itself will not work\n",
    "# Matplotlib will more than likely throw an error\n",
    "# Hence we needed to do \"torch.tensor(training_loss).detach().numpy()\"\n",
    "plt.plot(torch.tensor(torch_clf_model[1]).detach().numpy(), lw=3, label='train_loss')\n",
    "plt.plot(torch.tensor(torch_clf_model[2]).detach().numpy(), lw=3, label='val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's a nice looking graph above there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the training loss trending downwards, this suggest a few more epochs may make the mode perform even better\n",
    "# How did our model do for training\n",
    "# import some metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at y_true\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "# We see the values are continuous\n",
    "with torch.inference_mode():\n",
    "    test_preds = torch_clf_model[0](X_test)\n",
    "\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we try to feed this to some of our metrics algorithm, it will get a value error such as\n",
    "# \" Classification metrics can't handle a mix of binary and continuous targets\"\n",
    "# As a result, I round it out instead\n",
    "np.round(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save these predictions out to a variable\n",
    "x_test_preds = np.round(test_preds)\n",
    "x_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy score. \n",
    "# Grabbing the accuracy score\n",
    "# With that understanding above, let grab the accuracy score\n",
    "accuracy_score(y_true=y_test, y_pred=x_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a bad accuracy score\n",
    "# import seaborn\n",
    "# https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the confusion matrix, This does not seem so bad\n",
    "# We learned about metrics in notebook:\n",
    "#   10. Beginning Supervise Learning - Machine Learning - Logistic Regression, Decision Trees and Metrics\n",
    "sns.heatmap(confusion_matrix(y_true=y_test, y_pred=x_test_preds), annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above should help us to understand that accuracy is not the best measurement for imbalanced classification problems\n",
    "# Overall, this model is terrible. Context is important!!\n",
    "# This is actually a model, I would not put in production for my security monitoring\n",
    "# If I am able to ignore 41,509 records that's a good thing. \n",
    "# However, I have 13 false negatives. \n",
    "# This model also did not pick-up any true positives\n",
    "# Obviously, no one wants these false negatives. Hopefully, we can catch those \"threats\" via threat hunting\n",
    "# Looking at the classification report\n",
    "print(classification_report(y_true=y_test, y_pred=x_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming there are only 13 records flagged as suspicious\n",
    "len(list(np.where(y_test == 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a sample with the features values: \n",
    "# duration\torig_bytes\tresp_bytes\torig_pkts\torig_ip_bytes\tresp_pkts\tresp_ip_bytes\n",
    "new_sample = np.array([141., 356138566,\t11037090, 60, 3026679, 33, 982584], dtype=float, ndmin=2)\n",
    "\n",
    "# Preprocess the new samples as was done with the training data\n",
    "new_sample = pca.transform(min_max_scaler.transform(new_sample))\n",
    "\n",
    "# Convert the sample to a torch tensor\n",
    "new_sample = torch.tensor(data= new_sample, dtype=torch.float32)\n",
    "new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the sample\n",
    "# Remember, the previously unseen data has to go through the same transformation as the training data\n",
    "# See:\n",
    "#   06 - Beginning Data Scaling\n",
    "#   07 - Beginning Principal Component Analysis (PCA)\n",
    "torch_clf_model[0].eval()\n",
    "new_pred = torch_clf_model[0](new_sample)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data time library\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report a sample as suspicious, if it's threshold is greater than 0.5\n",
    "f'{datetime.now()} - [!] ALERT ** SUSPICIOUS ACTIVITY ** Zeek conn.log' if new_pred > 0.5  \\\n",
    "    else \"[**] {datetime.now()} - Normal Traffic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a suspicious sample\n",
    "new_sample = np.array([5000., 356138566,\t11037090, 6000, 3026679, 9999999, 982584], dtype=float, ndmin=2)\n",
    "\n",
    "# Preprocess the new samples as was done with the training data\n",
    "new_sample = pca.transform(min_max_scaler.transform(new_sample))\n",
    "\n",
    "# Convert the sample to a torch tensor\n",
    "new_sample = torch.tensor(data= new_sample, dtype=torch.float32)\n",
    "new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the sample\n",
    "new_pred = torch_clf_model[0](new_sample)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report a sample as suspicious, if it's threshold is greater than 0.5\n",
    "f'{datetime.now()} - [!] ALERT ** SUSPICIOUS ACTIVITY ** Zeek conn.log' if new_pred > 0.5  \\\n",
    "    else \"[**] {datetime.now()} - Normal Traffic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting, both instances we have true negative classification. \n",
    "# Remember, this model failed to find any true or false positives. \n",
    "# Hence we should not trust what was done here\n",
    "# Remember, the model also had false negatives. I would consider this a false negative.\n",
    "# If you want to know why I think so, hit me up for my opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os library\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the location to save the model\n",
    "PATH = './SAVED_MODELS/TORCH_classification/'\n",
    "MODELS_PATH = os.makedirs(name=PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(obj=torch_clf_model[0], f=F'{PATH}/torch_clf_model_saved_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_clf_torch_model = torch.load(f=f'{PATH}torch_clf_model_saved_dict.pth')\n",
    "loaded_clf_torch_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the loaded model\n",
    "loaded_clf_torch_model(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's it! Moving on!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcb100998b7ef434a33dbfac35f576e40d01f04c34d9ff6f6aad819b8a88c169"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
