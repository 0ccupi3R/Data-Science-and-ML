{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Nik Alleyne <br>\n",
    "Author Blog: **https://www.securitynik.com** <br>\n",
    "Author GitHub: **github.com/securitynik** <br>\n",
    "\n",
    "Author Books: [  <br>\n",
    "\n",
    "                \"https://www.amazon.ca/Learning-Practicing-Leveraging-Practical-Detection/dp/1731254458/\", \n",
    "                \n",
    "                \"https://www.amazon.ca/Learning-Practicing-Mastering-Network-Forensics/dp/1775383024/\" \n",
    "            ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why this series?\n",
    "When teaching the SANS SEC595: Applied Data Science and Machine Learning for Cybersecurity Professionals \n",
    "**https://www.sans.org/cyber-security-courses/applied-data-science-machine-learning/** I am always asked,\n",
    "\"Will you be sharing your demo notebooks?\" or \"Can we get a copy of your demo notebooks?\" or ... well you get the point.\n",
    "My answer is always no. Not that I do not want to share, (sharing is caring :-D) , but the demo notebooks \n",
    "by themselves, would not make sense or add real value. Hence, this series! \n",
    "\n",
    "This is my supplemental work, similar to what I would do in the demos but with a lot more details and references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Beginning Tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The series includes the following: <br>\n",
    "01 - Beginning Numpy <br>\n",
    "02 - Beginning Tensorflow  <br>\n",
    "03 - Beginning PyTorch <br>\n",
    "04 - Beginning Pandas <br>\n",
    "05 - Beginning Matplotlib <br>\n",
    "06 - Beginning Data Scaling <br>\n",
    "07 - Beginning Principal Component Analysis (PCA) <br>\n",
    "08 - Beginning Machine Learning Anomaly Detection - Isolation Forest and Local Outlier Factor <br>\n",
    "09 - Beginning Unsupervised Machine Learning - Clustering - K-means and DBSCAN <br>\n",
    "10 - Beginning Supervise Learning - Machine Learning - Logistic Regression, Decision Trees and Metrics <br>\n",
    "11 - Beginning Linear Regression - Machine Learning <br>\n",
    "12 - Beginning Deep Learning - Anomaly Detection with AutoEncoders, Tensorflow <br>\n",
    "13 - Beginning Deep Learning - Anomaly Detection with AutoEncoders, PyTroch <br>\n",
    "14 - Beginning Deep Learning - Linear Regression, Tensorflow <br>\n",
    "15 - Beginning Deep Learning - Linear Regression, PyTorch <br>\n",
    "16 - Beginning Deep Learning - Classification, Tensorflow <br>\n",
    "17 - Beginning Deep Learning - Classification, Pytorch <br>\n",
    "18 - Beginning Deep Learning - Classification - regression - MIMO - Functional API Tensorflow <br> \n",
    "19 - Beginning Deep Learning - Convolution Networks - Tensorflow <br>\n",
    "20 - Beginning Deep Learning - Convolution Networks - PyTorch <br>\n",
    "21 - Beginning Regularization - Early Stopping, Dropout, L2 (Ridge), L1 (Lasso) <br>\n",
    "22 - Beginning Model TFServing <br>\n",
    "\n",
    "But conn.log is not the only log file within Zeek. Let's build some models for DNS and HTTP logs. <br>\n",
    "I choose unsupervised, because there are no labels coming with these data. <br>\n",
    "\n",
    "23 - Continuing Anomaly Learning - Zeek DNS Log - Machine Learning <br>\n",
    "24 - Continuing Unsupervised Learning - Zeek HTTP Log - Machine Learning <br>\n",
    "\n",
    "This was a specific ask by someone in one of my class. <br>\n",
    "25 - Beginning - Reading Executables and Building a Neural Network to make predictions on suspicious vs suspicious  <br><br>\n",
    "\n",
    "With 25 notebooks in this series, it is quite possible there are things I could have or should have done differently.  <br>\n",
    "If you find any thing, you think fits those criteria, drop me a line. <br>\n",
    "\n",
    "If you find this series beneficial, I would greatly appreciate your feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tensorflow library\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First up, get the version of tensorflow being used\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow is a deep learning framework\n",
    "# While Numpy as seen in notebook \n",
    "#   01 - Beginning Numpy\n",
    "# cannot be used with GPU, Tensorflow can.\n",
    "# The system this notebook is being developed on does not have a GPU that is supported by Tensorflow\n",
    "# Confirming the devices currently available and we see only CPU\n",
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at it a different way\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the logical devices\n",
    "# We see only CPU\n",
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([10])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup an integer Tensor with 1 item\n",
    "# In a constant the values cannot be changed\n",
    "x = tf.constant(value=[10], name='tf_const')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Above we see tf.Tensor, we can confirm this is the type\n",
    "# We can confirm this is a Tensorflow Eager Tensor\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you wanted to, you can get the value of x as a numpy array\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can confirm this is a numpy array by looking at the type\n",
    "# We can learn more numpy in \n",
    "#   01 - Beginning Numpy\n",
    "type(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'tf_variable_int:0' shape=(3,) dtype=int32, numpy=array([10, 20, 30])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Tensor with multiple integer items\n",
    "# This time, transition to variable\n",
    "# Values in variables can be changed. Think weight or bias vectors that are \"trainable\"\n",
    "# Also assign x a name\n",
    "x = tf.Variable(initial_value=[10, 20, 30], name='tf_variable_int')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_variable_int:0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of x\n",
    "x.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'float_tensor:0' shape=(3,) dtype=float32, numpy=array([10., 20., 30.], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the tensor with multiple float variables\n",
    "x = tf.Variable(initial_value=[10., 20., 30.], name='float_tensor')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'casted_from_int_to_float:0' shape=(3,) dtype=float32, numpy=array([10., 20., 30.], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, cast the multiple item Tensor from integer to float\n",
    "# Notice the dtype is float32\n",
    "x =  tf.Variable(initial_value=[10, 20, 30], dtype=tf.float32, name='casted_from_int_to_float')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 3) dtype=float32, numpy=array([[10., 20., 30.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new dimension to the Tensor\n",
    "# Make it a 2 dimension Tensor\n",
    "# Notice the additional \"[\" and \"]\"\n",
    "x = tf.Variable([[10, 20, 30]], dtype=tf.float32 )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'tf_float_variable:0' shape=(1, 1, 3) dtype=float32, numpy=array([[[10., 20., 30.]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the Tensor to 3 dimensions\n",
    "# The output shape (1,1,3) tells us we have 1 group of 1x3.\n",
    "x = tf.Variable([[[10, 20, 30]]], dtype=tf.float32, name='tf_float_variable' )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[10.],\n",
       "       [20.],\n",
       "       [30.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the x tensor\n",
    "# In this case, (-1, 1) means any amount of rows but only one column\n",
    "# For this scenario, since x is 1 row and 3 columns, this transitions it to 3 rows and 1 column\n",
    "# Notice the transition from 1 to 2 dimensions\n",
    "x = tf.Variable([[[10, 20, 30]]], dtype=tf.float32, name='x_before_reshaped' )\n",
    "x = tf.reshape(x, [-1, 1], name='x_reshaped')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[10., 20., 30.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the x tensor\n",
    "# In this case, (1, -1) means only one row but any number of columns\n",
    "# For this scenario, since x is 1 row and 3 columns, this remains 1 row and 3 columns\n",
    "# Notice the transition from 1 to 2 dimensions\n",
    "x = tf.Variable([[[10, 20, 30]]], dtype=tf.float32, name='x_before_reshaped' )\n",
    "x = tf.reshape(x, [1, -1], name='x_reshaped')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'x_before_stack:0' shape=(5,) dtype=float32, numpy=array([1., 2., 3., 4., 5.], dtype=float32)>,\n",
       " <tf.Variable 'y_before_stack:0' shape=(5,) dtype=float32, numpy=array([6., 7., 8., 9., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two float tensors to stack\n",
    "x = tf.Variable(initial_value=[1, 2, 3, 4, 5], dtype=tf.float32, name='x_before_stack')\n",
    "y = tf.Variable(initial_value=[6, 7, 8, 9, 0], dtype=tf.float32, name='y_before_stack')\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[1., 2., 3., 4., 5.],\n",
       "       [6., 7., 8., 9., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack x and y vertically\n",
    "# Note this needs to be a list/array of items\n",
    "# This is very helpful, if you would like to stack two datasets to create 1\n",
    "# Maybe you have received new samples/observations\n",
    "z = tf.stack([x, y], axis=0, name='vertical_stack_of_x_y')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 2., 3., 4., 5., 6., 7., 8., 9., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate horizontally\n",
    "# This is helpful when you want to add new features to your dataset\n",
    "# Notice I added another dimension to both x and y in the 'values'\n",
    "# Remember this needs to be an array\n",
    "# Notice the axis=1\n",
    "z = tf.concat(values=[[x], [y]], axis=1, name='horizontal_stack_of+_x_y')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[5]], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the offset within x where the value equals 5\n",
    "x = tf.Variable(initial_value=[10, 9, 8, 7, 6, 5, 4], dtype=tf.float32)\n",
    "z = tf.where((x == 5))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming the return positioned within the Tensor\n",
    "x[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a 4*4 Tensor of ones\n",
    "tf.ones((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 6x6 Tensor with all zeros\n",
    "x = tf.zeros([6,6], dtype=tf.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[2., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the item at position row 0 and column 0 with 2\n",
    "# Counting for both the rows and columns start 0\n",
    "# As a result, even though this Tensor is 6x6, you \n",
    "# will be going from 0 to 5 for the indexes\n",
    "x = tf.tensor_scatter_nd_update(tensor=x, indices=[[0, 0]], updates=[2])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[  2.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 100.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the items at position row 3, column 5 with 100\n",
    "x = tf.tensor_scatter_nd_update(tensor=x, indices=[[3, 5]], updates=[100])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[  2.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 100.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,  23.,  24.,  25.,  26.,   0.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maybe instead, manipulate columns 1, 2 and 3 of the last row. \n",
    "# Remember, the last row is row 5\n",
    "x = tf.tensor_scatter_nd_update(tensor=x, indices=[[5, 1], [5, 2], [5, 3], [5, 4]], updates=[23, 24, 25, 26])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[  2.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0., -10., -10., -10., -10.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0., 100.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,  23.,  24.,  25.,  26.,   0.]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One more. Change the values from the last to the second column of row 2\n",
    "# Giving them a value of -10\n",
    "x = tf.tensor_scatter_nd_update(tensor=x, indices=[[1, 1], [1, 2], [1, 3], [1, 4]], \\\n",
    "                                updates=[-10, -10, -10, -10])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=100.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=100.0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the max value of all the items in the matrix\n",
    "# Using two different strategies\n",
    "tf.experimental.numpy.max(x), tf.reduce_max(input_tensor=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(6,), dtype=float32, numpy=array([  2.,  23.,  24.,  25.,  26., 100.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(6,), dtype=float32, numpy=array([  2.,  23.,  24.,  25.,  26., 100.], dtype=float32)>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the max value in the matrix going down the columns \n",
    "# Using two different strategies\n",
    "# Going across axis=0\n",
    "tf.experimental.numpy.max(x, axis=0), tf.reduce_max(input_tensor=x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(6,), dtype=float32, numpy=array([  2.,   0.,   0., 100.,   0.,  26.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(6,), dtype=float32, numpy=array([  2.,   0.,   0., 100.,   0.,  26.], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the max value in the matrix across each row\n",
    "# Using two different strategies\n",
    "tf.experimental.numpy.max(x, axis=1), tf.reduce_max(input_tensor=x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'tensor_before_transpose:0' shape=(1, 5) dtype=int32, numpy=array([[10,  9,  8,  7,  5]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an Tensor to be transposed\n",
    "x = tf.Variable(initial_value=[[10, 9, 8, 7, 5]], dtype=tf.int32, name='tensor_before_transpose')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int32, numpy=\n",
       "array([[10],\n",
       "       [ 9],\n",
       "       [ 8],\n",
       "       [ 7],\n",
       "       [ 5]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the full transpose function to change from a row vector to a column vector\n",
    "x = tf.transpose(a=x, name='x_transpose')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 4 * 4 eye matrix\n",
    "# Notice all the ones on the diagonal\n",
    "# This is helpful also when you think about one-hot encoding\n",
    "x = tf.eye(num_rows=4, num_columns=4, dtype=tf.float32, name='eye_matrix')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[6, 4, 3],\n",
       "       [9, 8, 0]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing to do some math\n",
    "# Define a Tensor with axes 0 and 1\n",
    "x = tf.constant([[6,4,3], [9, 8, 0]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sum of x\n",
    "x_sum = tf.reduce_sum(x)\n",
    "x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([13, 17])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rather than get the sum of the entire Tensor, \n",
    "# Get the sum of the rows, i.e axis=1\n",
    "x_sum = tf.reduce_sum(x, axis=1)\n",
    "x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([15, 12,  3])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly get the sum of the columns, i.e axis=0\n",
    "x_sum = tf.reduce_sum(x, axis=0)\n",
    "x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.3333335, 5.6666665], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average of the rows, axes=1\n",
    "# Notice I had to cast x's datatype from integer to float\n",
    "# if not, the returned average is an integer rather than a float\n",
    "x_avg = tf.reduce_mean(tf.cast(x=x, dtype=tf.float32), axis=1)\n",
    "x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([7.5, 6. , 1.5], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average of the rows, axes=1\n",
    "# Notice I had to cast x's datatype from integer to float\n",
    "# if not, the returned average is an integer rather than a float\n",
    "x_avg = tf.reduce_mean(tf.cast(x=x, dtype=tf.float32), axis=0)\n",
    "x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([7, 6, 1])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So I mentioned twice that I had to cast to get a float.\n",
    "# If not, the output is an integer\n",
    "# Let's try without casting to see what happens\n",
    "# As you can see, we seem to have gotten the floor of the values\n",
    "x_avg_without_cast = tf.reduce_mean(x, axis=0)\n",
    "x_avg_without_cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a random number between 10 and 20\n",
    "# Because I would like a scalar output, the shape is empty\n",
    "# At the same time, I would like an integer output, hence the dtype of tf.int32\n",
    "tf.random.uniform(shape=[], minval=10, maxval=20, dtype=tf.int32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 \t Num: 10\n",
      "Run: 1 \t Num: 10\n",
      "Run: 2 \t Num: 10\n",
      "Run: 3 \t Num: 10\n",
      "Run: 4 \t Num: 10\n"
     ]
    }
   ],
   "source": [
    "# You may have instances you wish to generate the same random number\n",
    "# Maybe for demonstration purposes. Like in this case.\n",
    "# In this case, first set the random seed\n",
    "\n",
    "for idx, item in enumerate(range(5)):\n",
    "    # Set the random seed\n",
    "    # Note, I'm using tf to set the seed. \n",
    "    # In the numpy notebook \n",
    "    #   01 - Beginning Numpy \n",
    "    # I set the seed using numpy\n",
    "    tf.random.set_seed(10)\n",
    "    \n",
    "    # Generate the number\n",
    "    print(f'Run: {idx} \\t Num: {tf.random.uniform(shape=[], minval=10, maxval=20, dtype=tf.int32).numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=1>,\n",
       " <tf.Variable 'Variable:0' shape=(5,) dtype=int32, numpy=array([ 2, 10,  5,  2,  3])>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In looking for max value within a Tensor, you might instead want the index of that value\n",
    "# The value returned is 1. We can see 10 at index position 1\n",
    "x = tf.Variable(initial_value=[2, 10, 5, 2, 3], dtype=tf.int32)\n",
    "tf.argmax(x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[2, 3, 4]])>,\n",
       " <tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
       " array([[5],\n",
       "        [4],\n",
       "        [3]])>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply two Tensors\n",
    "\n",
    "# First create the matrices \n",
    "x = tf.constant(value=[[2,3,4]], dtype=tf.int32)\n",
    "y = tf.constant(value=[[5],[4],[3]], dtype=tf.int32)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 3]), TensorShape([3, 1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the shape of the two Tensors\n",
    "# to confirm their inner dimensions are the same\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[34]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the dot product of the two vectors\n",
    "tf.tensordot(a=x, b=y, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[10, 15, 20],\n",
       "       [ 8, 12, 16],\n",
       "       [ 6,  9, 12]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, perform a pairwise or Hadamar product\n",
    "tf.multiply(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[2, 3, 4]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare to get the cumulative sum of the x vector\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cumulative sum of the Tensor\n",
    "# Notice how the first value in x remains the same, then the first and second are added\n",
    "# Then the second and third are added\n",
    "tf.cumsum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=int32, numpy=array([[[[2, 3, 4, 5, 6]]]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create x with 4 dimensions\n",
    "# Especially needed when working with convolution networks\n",
    "#   19 - Beginning Deep Learning, - Convolution Networks - Tensorflow\n",
    "#   20 - Beginning Deep Learning, - Convolution Networks, PyTorch\n",
    "x = tf.constant(value=[[[[2,3,4,5,6]]]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten x to a vector\n",
    "# Especially needed when working with convolution networks and then need to transition to a dense layer\n",
    "#   19 - Beginning Deep Learning, - Convolution Networks - Tensorflow\n",
    "#   20 - Beginning Deep Learning, - Convolution Networks, PyTorch\n",
    "tf.reshape(tensor=x, shape=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1, 1, 5), dtype=int32, numpy=array([[[[2, 3, 4, 5, 6]]]])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 3, 4, 5, 6])>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, we could have used tf.experimental.numpy.ravel() to get a 1D array\n",
    "x, tf.experimental.numpy.ravel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
       "array([[3, 4, 5],\n",
       "       [6, 7, 8]])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3*2 matrix\n",
    "x = tf.Variable([[3,4,5], [6,7,8]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[40, 10, 18],\n",
       "       [ 8,  5, 18]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One more before moving on, broadcasting\n",
    "# Taking a 2x3 matrix and multiple by a 1*3 vector\n",
    "# https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "tf.multiply(tf.constant(value=[[10,2,3], [2,1,3]]), tf.constant(value=[4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[40, 10, 18],\n",
       "       [ 8,  5, 18]])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above is the same as multiplying \n",
    "# [[10,2,3],   * [[4,5,6]\n",
    "# [2,1,3]]        [4,5,6]]\n",
    "tf.multiply(tf.Variable(initial_value=[[10,2,3], [2,1,3]]), tf.Variable(initial_value=[[4,5,6], [4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id.orig_h id.orig_p id.resp_h id.resp_p service duration orig_bytes resp_bytes orig_pkts orig_ip_bytes resp_pkts resp_ip_bytes',\n",
       "              array([b'192.168.0.31\\t58487\\t192.168.0.4\\t80\\t-\\t0.000065\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53542\\t192.168.0.4\\t9200\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55424\\t89.187.183.77\\t8888\\thttp\\t0.058498\\t208\\t976\\t6\\t528\\t5\\t1244',\n",
       "                     b'192.168.0.31\\t59079\\t192.168.0.4\\t80\\t-\\t0.000071\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58535\\t192.168.0.4\\t80\\t-\\t0.000051\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53343\\t192.168.0.4\\t9200\\t-\\t0.000047\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t54632\\t89.187.183.77\\t8888\\thttp\\t0.055387\\t208\\t976\\t6\\t516\\t6\\t1296',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58669\\t192.168.0.4\\t80\\t-\\t0.000116\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58175\\t192.168.0.4\\t80\\t-\\t0.000053\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t54410\\t192.168.0.2\\t53\\tdns\\t0.014004\\t35\\t81\\t1\\t63\\t1\\t109',\n",
       "                     b'192.168.0.31\\t58305\\t192.168.0.4\\t80\\t-\\t0.000029\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57813\\t192.168.0.4\\t80\\t-\\t0.000095\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55172\\t89.187.183.77\\t8888\\thttp\\t0.347983\\t227\\t593105\\t232\\t12287\\t134\\t255457',\n",
       "                     b'192.168.0.31\\t49994\\t192.168.0.2\\t53\\tdns\\t0.012986\\t46\\t178\\t1\\t74\\t1\\t206',\n",
       "                     b'192.168.0.31\\t57830\\t192.168.0.4\\t80\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t65497\\t239.255.255.250\\t1900\\t-\\t3.016811\\t680\\t0\\t4\\t792\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58198\\t162.159.129.83\\t443\\tssl\\t1.065813\\t1177\\t5639\\t10\\t1589\\t7\\t319',\n",
       "                     b'192.168.0.31\\t60546\\t192.168.0.2\\t53\\tdns\\t0.000001\\t36\\t36\\t1\\t64\\t1\\t64',\n",
       "                     b'192.168.0.31\\t58182\\t192.168.0.4\\t80\\t-\\t0.000065\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57655\\t52.96.230.194\\t443\\tssl\\t148.969018\\t9316\\t2935\\t13\\t4041\\t14\\t6301',\n",
       "                     b'192.168.0.4\\t38454\\t192.168.0.4\\t27761\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.8\\t43378\\t64.71.255.198\\t53\\tdns\\t0.017497\\t34\\t50\\t1\\t62\\t1\\t78',\n",
       "                     b'192.168.0.21\\t53428\\t192.168.0.4\\t9200\\t-\\t0.000053\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53584\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57774\\t192.168.0.4\\t80\\t-\\t0.000112\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59106\\t192.168.0.4\\t80\\t-\\t0.000089\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58526\\t52.114.142.107\\t443\\tssl\\t121.146995\\t1570\\t4426\\t7\\t1862\\t7\\t4718',\n",
       "                     b'192.168.0.31\\t59235\\t192.168.0.4\\t80\\t-\\t0.000022\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58178\\t192.168.0.4\\t80\\t-\\t0.000071\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58614\\t192.168.0.4\\t80\\t-\\t0.000107\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58383\\t192.168.0.4\\t80\\t-\\t0.000087\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t65069\\t208.67.222.222\\t53\\tdns\\t-\\t-\\t-\\t1\\t94\\t0\\t0',\n",
       "                     b'192.168.0.24\\t33028\\t192.46.228.115\\t443\\t-\\t3.030657\\t0\\t0\\t3\\t180\\t0\\t0',\n",
       "                     b'192.168.0.10\\t55870\\t89.187.183.77\\t8888\\thttp\\t0.304116\\t208\\t976\\t7\\t788\\t6\\t1308',\n",
       "                     b'192.168.0.21\\t53493\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t36472\\t192.168.0.2\\t53\\tdns\\t0.000632\\t97\\t97\\t2\\t153\\t2\\t153',\n",
       "                     b'192.168.0.31\\t65128\\t192.168.0.2\\t53\\tdns\\t0.000001\\t31\\t47\\t1\\t59\\t1\\t75',\n",
       "                     b'192.168.0.31\\t58630\\t192.168.0.4\\t80\\t-\\t0.000130\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59044\\t165.75.68.247\\t52311\\t-\\t-\\t-\\t-\\t1\\t52\\t0\\t0',\n",
       "                     b'192.168.0.10\\t54030\\t89.187.183.77\\t8888\\thttp\\t0.065296\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.31\\t58092\\t192.168.0.4\\t80\\t-\\t0.000058\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58774\\t192.168.0.4\\t80\\t-\\t0.000072\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t8\\t165.75.68.247\\t0\\t-\\t1.352142\\t156\\t0\\t39\\t1248\\t0\\t0',\n",
       "                     b'192.168.0.31\\t59131\\t192.168.0.4\\t80\\t-\\t0.000191\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53451\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59216\\t192.168.0.4\\t80\\t-\\t0.000088\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59189\\t192.168.0.4\\t80\\t-\\t0.000088\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58329\\t192.168.0.4\\t80\\t-\\t0.000011\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53566\\t89.187.183.77\\t8888\\thttp\\t0.048473\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.31\\t58537\\t192.168.0.4\\t80\\t-\\t0.000061\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59092\\t192.168.0.4\\t80\\t-\\t0.000081\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53418\\t89.187.183.77\\t8888\\thttp\\t0.056540\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.21\\t53459\\t192.168.0.4\\t9200\\t-\\t0.000053\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58339\\t192.168.0.4\\t80\\t-\\t0.000011\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53584\\t89.187.183.77\\t8888\\thttp\\t0.318972\\t227\\t454726\\t174\\t9283\\t66\\t130918',\n",
       "                     b'192.168.0.10\\t55498\\t89.187.183.77\\t8888\\thttp\\t0.056971\\t208\\t976\\t6\\t516\\t6\\t1296',\n",
       "                     b'192.168.0.31\\t58670\\t192.168.0.4\\t80\\t-\\t0.000033\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59185\\t192.168.0.4\\t80\\t-\\t0.000043\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53472\\t89.187.183.77\\t8888\\thttp\\t0.060901\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.21\\t53601\\t192.168.0.4\\t9200\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59226\\t192.168.0.2\\t53\\tdns\\t0.040338\\t44\\t106\\t1\\t72\\t1\\t134',\n",
       "                     b'192.168.0.31\\t59185\\t192.168.0.4\\t80\\t-\\t0.000081\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t54806\\t89.187.183.77\\t8888\\thttp\\t0.057076\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'127.0.0.1\\t51776\\t127.0.0.1\\t27762\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t57855\\t192.168.0.4\\t80\\t-\\t0.000045\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'127.0.0.1\\t58559\\t127.0.0.53\\t53\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.10\\t54386\\t89.187.183.77\\t8888\\thttp\\t0.283546\\t208\\t976\\t7\\t776\\t7\\t1360',\n",
       "                     b'192.168.0.31\\t58299\\t192.168.0.4\\t80\\t-\\t0.000117\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58759\\t192.168.0.4\\t80\\t-\\t0.000056\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53038\\t89.187.183.77\\t8888\\thttp\\t0.060016\\t208\\t977\\t6\\t528\\t5\\t1245',\n",
       "                     b'192.168.0.31\\t58449\\t192.168.0.4\\t80\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.62\\t64300\\t192.168.0.2\\t53\\tdns\\t0.015724\\t40\\t113\\t1\\t68\\t1\\t141',\n",
       "                     b'192.168.0.21\\t53462\\t192.168.0.4\\t9200\\t-\\t0.000053\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53340\\t104.93.164.172\\t80\\thttp\\t60.267515\\t227\\t263\\t8\\t571\\t7\\t818',\n",
       "                     b'192.168.0.31\\t58637\\t192.168.0.4\\t80\\t-\\t0.000051\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t54988\\t89.187.183.77\\t8888\\thttp\\t0.777435\\t227\\t608136\\t222\\t11875\\t127\\t193380',\n",
       "                     b'192.168.0.10\\t53280\\t89.187.183.77\\t8888\\thttp\\t0.232831\\t227\\t304336\\t177\\t9439\\t60\\t125016',\n",
       "                     b'192.168.0.31\\t58146\\t192.168.0.4\\t80\\t-\\t0.000078\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53379\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58466\\t192.168.0.4\\t80\\t-\\t0.000080\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58757\\t192.168.0.4\\t80\\t-\\t0.000117\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58442\\t192.168.0.4\\t80\\t-\\t0.000105\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t54052\\t89.187.183.77\\t8888\\t-\\t0.000023\\t0\\t0\\t1\\t40\\t1\\t52',\n",
       "                     b'192.168.0.10\\t54002\\t89.187.183.77\\t8888\\thttp\\t0.057504\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.31\\t58698\\t192.168.0.4\\t80\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58440\\t192.168.0.4\\t80\\t-\\t0.000058\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53495\\t192.168.0.4\\t9200\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53409\\t192.168.0.4\\t9200\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t64215\\t192.168.0.2\\t53\\tdns\\t0.010563\\t33\\t49\\t1\\t61\\t1\\t77',\n",
       "                     b'192.168.0.21\\t53471\\t192.168.0.4\\t9200\\t-\\t0.000056\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53384\\t192.168.0.4\\t9200\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58254\\t52.96.230.194\\t443\\tssl\\t123.839827\\t54508\\t19392\\t55\\t21725\\t53\\t18254',\n",
       "                     b'192.168.0.31\\t58321\\t192.168.0.4\\t80\\t-\\t0.000091\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57513\\t192.168.0.4\\t80\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t59107\\t192.168.0.4\\t80\\t-\\t0.000130\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58624\\t192.168.0.4\\t80\\t-\\t0.000060\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58087\\t192.168.0.4\\t80\\t-\\t0.000027\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58287\\t192.168.0.4\\t80\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55434\\t89.187.183.77\\t8888\\thttp\\t0.380715\\t227\\t487825\\t213\\t11311\\t75\\t209373',\n",
       "                     b'192.168.0.31\\t57582\\t192.168.0.4\\t80\\t-\\t0.000053\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57836\\t192.168.0.4\\t80\\t-\\t0.000101\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53458\\t192.168.0.4\\t9200\\t-\\t0.000059\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53593\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t54740\\t89.187.183.77\\t8888\\thttp\\t0.360780\\t227\\t662279\\t223\\t11831\\t286\\t432447',\n",
       "                     b'192.168.0.31\\t58361\\t192.168.0.4\\t80\\t-\\t0.000034\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57711\\t192.168.0.4\\t80\\t-\\t0.000077\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58038\\t192.168.0.4\\t80\\t-\\t0.000058\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53356\\t192.168.0.4\\t9200\\t-\\t0.000067\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53492\\t192.168.0.4\\t9200\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53583\\t192.168.0.4\\t9200\\t-\\t0.000056\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58621\\t192.168.0.4\\t80\\t-\\t0.000089\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58603\\t192.168.0.4\\t80\\t-\\t0.000034\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53361\\t192.168.0.4\\t9200\\t-\\t0.000056\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57867\\t192.168.0.4\\t80\\t-\\t0.000066\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57739\\t192.168.0.4\\t80\\t-\\t0.000095\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59108\\t192.168.0.4\\t80\\t-\\t0.000138\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53508\\t192.168.0.4\\t9200\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59138\\t192.168.0.4\\t80\\t-\\t0.000104\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t54436\\t89.187.183.77\\t8888\\thttp\\t0.400640\\t227\\t563024\\t180\\t9595\\t72\\t209120',\n",
       "                     b'192.168.0.31\\t58568\\t165.75.68.247\\t52311\\t-\\t-\\t-\\t-\\t1\\t52\\t0\\t0',\n",
       "                     b'192.168.0.21\\t53298\\t52.137.108.250\\t443\\tssl\\t0.733075\\t2692\\t10035\\t13\\t3224\\t15\\t5554',\n",
       "                     b'192.168.0.31\\t59207\\t192.168.0.4\\t80\\t-\\t0.000075\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57812\\t192.168.0.4\\t80\\t-\\t0.000206\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58159\\t192.168.0.4\\t80\\t-\\t0.000010\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53581\\t192.168.0.4\\t9200\\t-\\t0.000024\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55486\\t89.187.183.77\\t8888\\thttp\\t0.052656\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.21\\t53454\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58315\\t192.168.0.4\\t80\\t-\\t0.000126\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57724\\t192.168.0.4\\t80\\t-\\t0.000059\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58050\\t192.168.0.4\\t80\\t-\\t0.000059\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53629\\t192.168.0.4\\t9200\\t-\\t0.000058\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53626\\t192.168.0.4\\t9200\\t-\\t0.000053\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58072\\t192.168.0.4\\t80\\t-\\t0.000059\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58258\\t192.168.0.4\\t80\\t-\\t0.000037\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58795\\t192.168.0.4\\t80\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53808\\t89.187.183.77\\t8888\\thttp\\t0.063758\\t208\\t976\\t5\\t476\\t5\\t1244',\n",
       "                     b'fe80::ce25:4f71:339:bac9\\t61913\\tff02::1:3\\t5355\\tdns\\t0.412213\\t78\\t0\\t2\\t174\\t0\\t0',\n",
       "                     b'192.168.0.10\\t55988\\t89.187.183.77\\t8888\\thttp\\t0.470586\\t227\\t265232\\t129\\t7170\\t60\\t119228',\n",
       "                     b'192.168.0.31\\t57729\\t192.168.0.4\\t80\\t-\\t0.000126\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58680\\t192.168.0.4\\t80\\t-\\t0.000090\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58299\\t192.168.0.4\\t80\\t-\\t0.000037\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t46922\\t192.168.0.4\\t27761\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t59235\\t192.168.0.4\\t80\\t-\\t0.000051\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53647\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57769\\t192.168.0.4\\t80\\t-\\t0.000076\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'127.0.0.1\\t51776\\t127.0.0.1\\t27762\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.10\\t54616\\t89.187.183.77\\t8888\\thttp\\t0.061118\\t208\\t976\\t5\\t476\\t5\\t1244',\n",
       "                     b'192.168.0.21\\t53556\\t192.168.0.4\\t9200\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58544\\t192.168.0.4\\t80\\t-\\t0.000056\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58805\\t192.168.0.4\\t80\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.32\\t35982\\t192.168.0.2\\t53\\tdns\\t0.000001\\t35\\t51\\t1\\t63\\t1\\t79',\n",
       "                     b'192.168.0.31\\t58130\\t192.168.0.4\\t80\\t-\\t0.000096\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58290\\t192.168.0.4\\t80\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.32\\t47705\\t206.108.0.132\\t123\\tntp\\t0.013160\\t48\\t48\\t1\\t76\\t1\\t76',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t59124\\t192.168.0.4\\t80\\t-\\t0.000120\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53367\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58066\\t192.168.0.4\\t80\\t-\\t0.000158\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t48786\\t192.168.0.4\\t27761\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58168\\t192.168.0.4\\t80\\t-\\t0.000078\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58105\\t192.168.0.4\\t80\\t-\\t0.000062\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58647\\t192.168.0.4\\t80\\t-\\t0.000016\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57869\\t192.168.0.4\\t80\\t-\\t0.000114\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t49741\\t239.255.255.250\\t3702\\t-\\t5.321674\\t4592\\t0\\t7\\t4788\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58396\\t192.168.0.4\\t80\\t-\\t0.000102\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58055\\t192.168.0.4\\t80\\t-\\t0.000090\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'127.0.0.1\\t51776\\t127.0.0.1\\t27762\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t53455\\t192.168.0.2\\t53\\tdns\\t0.031606\\t38\\t150\\t1\\t66\\t1\\t178',\n",
       "                     b'192.168.0.31\\t58616\\t192.168.0.4\\t80\\t-\\t0.000010\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57979\\t192.168.0.4\\t80\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53508\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t5353\\t224.0.0.251\\t5353\\tdns\\t1.001576\\t86\\t0\\t2\\t142\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58142\\t192.168.0.4\\t80\\t-\\t0.000078\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t60537\\t192.168.0.2\\t53\\tdns\\t0.000138\\t44\\t44\\t1\\t72\\t1\\t72',\n",
       "                     b'192.168.0.4\\t38454\\t192.168.0.4\\t27761\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.21\\t53627\\t192.168.0.4\\t9200\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t53435\\t192.168.0.2\\t53\\tdns\\t0.018080\\t33\\t49\\t1\\t61\\t1\\t77',\n",
       "                     b'192.168.0.31\\t58317\\t192.168.0.4\\t80\\t-\\t0.000125\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53555\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53652\\t89.187.183.77\\t8888\\thttp\\t0.433324\\t227\\t502854\\t200\\t10635\\t107\\t221722',\n",
       "                     b'192.168.0.10\\t54858\\t89.187.183.77\\t8888\\thttp\\t0.227163\\t227\\t265231\\t139\\t7463\\t56\\t100183',\n",
       "                     b'192.168.0.10\\t53394\\t89.187.183.77\\t8888\\thttp\\t0.311764\\t227\\t472783\\t163\\t8711\\t82\\t264199',\n",
       "                     b'192.168.0.10\\t55948\\t89.187.183.77\\t8888\\thttp\\t0.054200\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.10\\t56018\\t89.187.183.77\\t8888\\thttp\\t0.055214\\t208\\t976\\t6\\t516\\t6\\t1296',\n",
       "                     b'127.0.0.1\\t51776\\t127.0.0.1\\t27762\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.10\\t55974\\t89.187.183.77\\t8888\\thttp\\t0.055632\\t208\\t976\\t6\\t528\\t5\\t1244',\n",
       "                     b'192.168.0.31\\t59129\\t192.168.0.4\\t80\\t-\\t0.000116\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55072\\t89.187.183.77\\t8888\\thttp\\t0.438529\\t227\\t698384\\t230\\t12195\\t147\\t270188',\n",
       "                     b'192.168.0.31\\t58371\\t192.168.0.4\\t80\\t-\\t0.000091\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57760\\t192.168.0.4\\t80\\t-\\t0.000096\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59139\\t192.168.0.4\\t80\\t-\\t0.000115\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58355\\t192.168.0.4\\t80\\t-\\t0.000082\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53583\\t192.168.0.4\\t9200\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57794\\t192.168.0.4\\t80\\t-\\t0.000057\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t60444\\t64.71.255.198\\t53\\tdns\\t0.018940\\t38\\t167\\t1\\t66\\t1\\t195',\n",
       "                     b'192.168.0.31\\t58652\\t192.168.0.4\\t80\\t-\\t0.000067\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53488\\t192.168.0.4\\t9200\\t-\\t0.000042\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t52946\\t89.187.183.77\\t8888\\thttp\\t0.052405\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.31\\t59146\\t192.168.0.4\\t80\\t-\\t0.000103\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58637\\t192.168.0.4\\t80\\t-\\t0.000057\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t50821\\t192.168.0.2\\t53\\tdns\\t0.022855\\t97\\t171\\t2\\t153\\t2\\t227',\n",
       "                     b'192.168.0.31\\t57804\\t192.168.0.4\\t80\\t-\\t0.000114\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55350\\t89.187.183.77\\t8888\\thttp\\t0.606589\\t227\\t689350\\t231\\t12474\\t266\\t403466',\n",
       "                     b'192.168.0.21\\t53334\\t192.168.0.4\\t9200\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59106\\t192.168.0.4\\t80\\t-\\t0.000009\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58700\\t192.168.0.4\\t80\\t-\\t0.000080\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58098\\t192.168.0.4\\t80\\t-\\t0.000096\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53446\\t192.168.0.4\\t9200\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t57780\\t192.168.0.4\\t80\\t-\\t0.000097\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58709\\t192.168.0.4\\t80\\t-\\t0.000123\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58065\\t192.168.0.4\\t80\\t-\\t0.000173\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t54144\\t89.187.183.77\\t8888\\thttp\\t0.435265\\t227\\t572039\\t190\\t10115\\t96\\t232415',\n",
       "                     b'192.168.0.10\\t54466\\t89.187.183.77\\t8888\\thttp\\t0.060426\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.31\\t58054\\t192.168.0.4\\t80\\t-\\t0.000075\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.21\\t53510\\t20.50.73.9\\t443\\tssl\\t1.115947\\t1760\\t6762\\t14\\t2332\\t7\\t4134',\n",
       "                     b'192.168.0.31\\t59200\\t192.168.0.4\\t80\\t-\\t0.000104\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'127.0.0.1\\t51776\\t127.0.0.1\\t27762\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t59131\\t192.168.0.4\\t80\\t-\\t0.000097\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t53744\\t89.187.183.77\\t8888\\thttp\\t0.057180\\t208\\t976\\t6\\t528\\t6\\t1296',\n",
       "                     b'192.168.0.10\\t54650\\t89.187.183.77\\t8888\\thttp\\t0.368643\\t227\\t550992\\t175\\t9335\\t82\\t210640',\n",
       "                     b'192.168.0.21\\t53434\\t192.168.0.4\\t9200\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55666\\t89.187.183.77\\t8888\\thttp\\t0.307682\\t227\\t406609\\t158\\t8451\\t73\\t154117',\n",
       "                     b'192.168.0.31\\t57788\\t192.168.0.4\\t80\\t-\\t0.000064\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t38454\\t192.168.0.4\\t27761\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38454\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58164\\t192.168.0.4\\t80\\t-\\t0.000072\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t60557\\t224.0.0.252\\t5355\\tdns\\t0.425820\\t78\\t0\\t2\\t134\\t0\\t0',\n",
       "                     b'192.168.0.31\\t59137\\t192.168.0.4\\t80\\t-\\t0.000095\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58951\\t165.75.68.247\\t52311\\t-\\t3.017689\\t0\\t0\\t3\\t156\\t0\\t0',\n",
       "                     b'192.168.0.31\\t58772\\t192.168.0.4\\t80\\t-\\t0.000052\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58367\\t192.168.0.4\\t80\\t-\\t0.000087\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t38454\\t192.168.0.4\\t27761\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t61747\\t64.71.255.204\\t53\\tdns\\t-\\t-\\t-\\t1\\t63\\t0\\t0',\n",
       "                     b'192.168.0.8\\t55146\\t64.71.255.198\\t53\\tdns\\t0.011336\\t34\\t50\\t1\\t62\\t1\\t78',\n",
       "                     b'192.168.0.10\\t54068\\t89.187.183.77\\t8888\\t-\\t-\\t-\\t-\\t0\\t0\\t1\\t52',\n",
       "                     b'192.168.0.31\\t58115\\t192.168.0.4\\t80\\t-\\t0.000078\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58507\\t192.168.110.2\\t53\\tdns\\t-\\t-\\t-\\t1\\t63\\t0\\t0',\n",
       "                     b'192.168.0.31\\t57711\\t192.168.0.4\\t80\\t-\\t0.000061\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55254\\t89.187.183.77\\t8888\\thttp\\t0.309038\\t208\\t976\\t7\\t776\\t7\\t1360',\n",
       "                     b'192.168.0.31\\t59082\\t192.168.0.4\\t80\\t-\\t0.000094\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t59081\\t192.168.0.4\\t80\\t-\\t0.000055\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.31\\t58536\\t192.168.0.4\\t80\\t-\\t0.000058\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.10\\t55478\\t89.187.183.77\\t8888\\thttp\\t0.055786\\t208\\t977\\t6\\t528\\t6\\t1297',\n",
       "                     b'192.168.0.10\\t53432\\t89.187.183.77\\t8888\\thttp\\t0.054020\\t208\\t977\\t5\\t476\\t5\\t1245',\n",
       "                     b'192.168.0.31\\t57867\\t192.168.0.4\\t80\\t-\\t0.000054\\t0\\t0\\t1\\t52\\t1\\t40',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.10\\t55068\\t89.187.183.77\\t8888\\thttp\\t0.414633\\t227\\t635217\\t220\\t11675\\t124\\t220305',\n",
       "                     b'192.168.0.31\\t55296\\t192.168.0.2\\t53\\tdns\\t0.000266\\t39\\t39\\t1\\t67\\t1\\t67',\n",
       "                     b'192.168.0.10\\t55648\\t89.187.183.77\\t8888\\thttp\\t0.057661\\t208\\t977\\t6\\t516\\t6\\t1297',\n",
       "                     b'192.168.0.4\\t27761\\t192.168.0.4\\t38478\\t-\\t-\\t-\\t-\\t0\\t0\\t0\\t0',\n",
       "                     b'192.168.0.31\\t59114\\t192.168.0.4\\t80\\t-\\t0.000070\\t0\\t0\\t1\\t52\\t1\\t40'],\n",
       "                    dtype=object))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# While I typically will use Pandas to read in data,\n",
    "#   04 - Beginning Pandas <br>\n",
    "# You also have the opportunity to do so with numpy\n",
    "# Maybe you want to read in content from a .csv file in batches. \n",
    "# In this case, batches of 256\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset\n",
    "next(tf.data.experimental.make_csv_dataset(file_pattern='conn.log', \\\n",
    "                                           header=True, batch_size=256, field_delim=',').as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional References and good reads/videos <br>: <br>\n",
    "https://www.tensorflow.org/guide/tensor <br>\n",
    "https://medium.com/@schartz/the-shape-of-tensor-bab75001d7bc <br>\n",
    "https://towardsdatascience.com/how-to-replace-values-by-index-in-a-tensor-with-tensorflow-2-0-510994fe6c5f <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/math/reduce_max <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/eye <br>\n",
    "https://pytorch.org/docs/stable/generated/torch.tensordot.html <br>\n",
    "https://www.tensorflow.org/guide/tensor <br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/utils/text_dataset_from_directory <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcb100998b7ef434a33dbfac35f576e40d01f04c34d9ff6f6aad819b8a88c169"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
