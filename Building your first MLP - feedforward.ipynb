{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn the previous notebook, I built a simple feed forward, single neuron network\\n\\nIn this post, I am building on top of what was done previously. This time, I will add a hidden layer\\n\\nReferences:\\nhttps://www.youtube.com/watch?v=0oWnheK-gGk&list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&index=6\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In the previous notebook, I built a simple feed forward, single neuron network\n",
    "\n",
    "In this post, I am building on top of what was done previously. This time, I will add a hidden layer\n",
    "\n",
    "References:\n",
    "https://www.youtube.com/watch?v=0oWnheK-gGk&list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&index=6\n",
    "\n",
    "\n",
    "This needs to be complted. Maybe rebuild the entire network later. Continue this you tube series\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class\n",
    "class simple_feed_forward_mlp:\n",
    "    ''' This class implements my simple feed forward MLP '''\n",
    "    \n",
    "    def __init__(self, X_input_data=[]):\n",
    "        ''' Setup the init function '''\n",
    "        # initialize the variables\n",
    "        self.X_input_data = np.array(X_input_data)\n",
    "        \n",
    "        # Label\n",
    "        self.output_label = 1\n",
    "\n",
    "        # Setup a single input layer\n",
    "        self.hidden_layers_count = 1\n",
    "\n",
    "        # Setup the neuron in the single layer\n",
    "        self.input_layers_neurons_count = 3\n",
    "\n",
    "        # Setup a single output layer\n",
    "        self.output_layer_count = 1\n",
    "\n",
    "        # Setup the weights matrix for the first layer -> Input to hidden\n",
    "        self.weights_vector_1 = np.random.rand(len(X_input_data) * 3)\n",
    "\n",
    "        # Setup the weights matrix for the second layer -> hidden to output\n",
    "        self.weights_vector_2 = np.random.rand(self.input_layers_neurons_count)\n",
    "\n",
    "        # initialize the hidden layer weighted sum to 0\n",
    "        self.weighted_sum_first_layer = 0\n",
    "\n",
    "        print(f'Input data: {self.X_input_data}')\n",
    "        print(f'Number of hidden layers: {self.hidden_layers_count}')\n",
    "        print(f'Input to hidden layer weights : {self.weights_vector_1}')\n",
    "        print(f'Hidden to output layer weights : {self.weights_vector_2}')\n",
    "        print('There are 3 nodes in the 1 input layer: ')\n",
    "\n",
    "    # Define the sigmoid activation function\n",
    "    def sigmoid_activation(self, weighted_sum):\n",
    "        ''' Returns the sigmoid of the weighted sum'''\n",
    "        self.weighted_sum = weighted_sum\n",
    "        return 1 / (1 + np.exp(-self.weighted_sum))\n",
    "\n",
    "    # Define the loss function\n",
    "    def error_function_mse(self, y_truth, y_predict):\n",
    "        ''' Calculates the MSE '''            \n",
    "        self.y_truth = y_truth\n",
    "        self.y_predict = y_predict\n",
    "        return ((self.y_truth - self.y_predict) ** 2)  \n",
    "\n",
    "    def feed_forward(self):\n",
    "        ''' Define the feed forward part of the network '''\n",
    "        self.weighted_sum_first_layer = np.dot(self.weights_vector_1.reshape(-1,len(self.X_input_data)), self.X_input_data)\n",
    "        print(f'First layer -> input to hidden weighted sum: {self.weighted_sum_first_layer}')\n",
    "\n",
    "        self.first_layer_sigmoid = [ self.sigmoid_activation(item) for item in self.weighted_sum_first_layer ]\n",
    "        print(f'Hidden layer sigmoid: {self.first_layer_sigmoid}')\n",
    "\n",
    "        self.weighted_sum_second_layer = np.dot(self.weights_vector_2, self.first_layer_sigmoid)            \n",
    "\n",
    "        print(f'Hidden to output weights vector: {self.weights_vector_2}')\n",
    "        print(f'Hidden to output weighted sum: {self.weighted_sum_second_layer}')\n",
    "\n",
    "        self.prediction = np.round(self.sigmoid_activation(self.weighted_sum_second_layer),1)\n",
    "        self.error_loss = self.error_function_mse(self.output_label, self.prediction)\n",
    "        print(f'The feed forward network predicted: {self.prediction}, expected output is: 1')\n",
    "        print(f'The current loss is: {self.error_loss}')  \n",
    "\n",
    "    # Implement backpropagation\n",
    "    def backpropagation(self, error):\n",
    "        ''' Implement backpropagation '''\n",
    "        self.error = self.error_loss\n",
    "\n",
    "        # need the dw/\n",
    "        \n",
    "        # Read the error which was calculated\n",
    "\n",
    "        print('Performing back propagation ...')\n",
    "        print(f'Received error is: {self.error}')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: [2 9]\n",
      "Number of hidden layers: 1\n",
      "Input to hidden layer weights : [0.91777412 0.71457578 0.54254437 0.14217005 0.37334076 0.67413362]\n",
      "Hidden to output layer weights : [0.44183317 0.43401399 0.61776698]\n",
      "There are 3 nodes in the 1 input layer: \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mlp = simple_feed_forward_mlp(X_input_data=[2, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.667962929347152"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.sigmoid_activation(0.6989860557314004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer -> input to hidden weighted sum: [8.2667303  2.36461916 6.81388406]\n",
      "Hidden layer sigmoid: [0.9997431420081266, 0.9140892434604174, 0.9989027869128116]\n",
      "Hidden to output weights vector: [0.44183317 0.43401399 0.61776698]\n",
      "Hidden to output weighted sum: 1.4555363653140436\n",
      "The feed forward network predicted: 0.8, expected output is: 1\n",
      "The current loss is: 0.03999999999999998\n"
     ]
    }
   ],
   "source": [
    "mlp.feed_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03999999999999998"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.error_function_mse(1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.output_layer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing back propagation ...\n",
      "Received error is: 0.03999999999999998\n"
     ]
    }
   ],
   "source": [
    "mlp.backpropagation(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [4.5, 0.9, 0.8]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ sigmoid(item) for item in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d33f85780c2c83edc5278292945a20a0a252a43de143ff59f2c10c2359881c2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
