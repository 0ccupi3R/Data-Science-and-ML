{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nCurrently following TensorFlow from the ground up.\\n\\nKey points\\n- While you don't need Python to use TensorFlow, you almost always build your models and do training using Python\\n- The arc of machine learning is:\\n    Collect data -> Represent the weights (Parameters) -> Build our model out of groups of weights -> Train those weights -> Accelerate the training\\n\\n- Tensorflow Layers\\n\\n        TF Probability TFX,\\n            |   |\\n        Keras   Sonet   \\n            |   |\\n            TF Graph\\n        Eager   Compilation\\n            |   |\\n            Runtime\\n\\n             |  |\\n            Kernels\\n\\n5 Key pieces to keep in mind when using TensorFlow\\n    1.  Tensors - Used to represent data\\n        a. These are also strongly typed. eg.\\n            floats, ints, boleans, strings, sparse, ragged, etc.\\n        b. They are immutable, as in, unable to update them but will create a new one\\n        c. Everything is turned to a tensor. Images, sounds, text, etc.\\n        d. They are also fast, can be vectorized and used on accelerators\\n        e. It has a shape\\n        f. Has axes or dimensions \\n        g. Has a size\\n    2.  Variables - used to represent weights\\n        1. A variables acts and looks like a tensor\\n    3.  Modules - Used to build the models\\n    4.  Gradients tapes - Used to train the model\\n        1. Automatic differentation\\n        2. To do machine learning, you have to take a lot of gradients\\n        3. Records per operation gradient functions\\n        4. Only records the computation that actually took place\\n    5.  tf.function - Usedto accelrate the training\\n    \\nReferences:\\n\\n\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Currently following TensorFlow from the ground up.\n",
    "\n",
    "Key points\n",
    "- While you don't need Python to use TensorFlow, you almost always build your models and do training using Python\n",
    "- The arc of machine learning is:\n",
    "    Collect data -> Represent the weights (Parameters) -> Build our model out of groups of weights -> Train those weights -> Accelerate the training\n",
    "\n",
    "- Tensorflow Layers\n",
    "\n",
    "        TF Probability TFX,\n",
    "            |   |\n",
    "        Keras   Sonet   \n",
    "            |   |\n",
    "            TF Graph\n",
    "        Eager   Compilation\n",
    "            |   |\n",
    "            Runtime\n",
    "\n",
    "             |  |\n",
    "            Kernels\n",
    "\n",
    "5 Key pieces to keep in mind when using TensorFlow\n",
    "    1.  Tensors - Used to represent data\n",
    "        a. These are also strongly typed. eg.\n",
    "            floats, ints, boleans, strings, sparse, ragged, etc.\n",
    "        b. They are immutable, as in, unable to update them but will create a new one\n",
    "        c. Everything is turned to a tensor. Images, sounds, text, etc.\n",
    "        d. They are also fast, can be vectorized and used on accelerators\n",
    "        e. It has a shape\n",
    "        f. Has axes or dimensions \n",
    "        g. Has a size\n",
    "    2.  Variables - used to represent weights\n",
    "        1. A variables acts and looks like a tensor\n",
    "    3.  Modules - Used to build the models\n",
    "    4.  Gradients tapes - Used to train the model\n",
    "        1. Automatic differentation\n",
    "        2. To do machine learning, you have to take a lot of gradients\n",
    "        3. Records per operation gradient functions\n",
    "        4. Only records the computation that actually took place\n",
    "        5. Can watch any variables\n",
    "    5.  tf.function - Usedto accelrate the training\n",
    "    \n",
    "References:\n",
    "https://youtu.be/3LLZzi48iB8\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow library\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of tensorflow devices\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Closer look at tensors\n",
    "# Create a float tensor with a scalar\n",
    "# Basically a rank 0 tensor\n",
    "#This has a dtype of float32\n",
    "tf.constant(10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This has a dtype of int\n",
    "# Same here. Rank 0 or scalar.\n",
    "tf.constant(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([10.5,  4.6], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at a rank 1 tensor of dtype float32.\n",
    "tf.constant([10.5, 4.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=complex64, numpy=array([4.1+7.3j, 5.2+8.2j, 6.3+9.1j], dtype=complex64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A more complext tensor\n",
    "tf.complex(tf.constant([4.1,5.2,6.3]), tf.constant([7.3,8.2,9.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=string, numpy=\n",
       "array([[b'mangoes', b'star apples'],\n",
       "       [b'guava', b'cherries'],\n",
       "       [b'securitynik', b'Test']], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a string rank 2 tensor\n",
    "tf.constant([['mangoes', 'star apples'], ['guava', 'cherries'], ['securitynik', 'Test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 4, 5), dtype=int32, numpy=\n",
       "array([[[[0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0]]]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at a rank 4 tensor\n",
    "# This will have 3 batches of width 2 with 4 rows and 5 columns\n",
    "rank_4_tensor = tf.zeros(shape=(3,2,4,5), dtype='int32')\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the type of elements in rank_4_tensor\n",
    "rank_4_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dimensions in rank_4_tensor\n",
    "rank_4_tensor.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2, 4, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the rank_4_tensor\n",
    "rank_4_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of elements in the rank_4_tensor\n",
    "# This will be 3*2*4*5\n",
    "tf.size(rank_4_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2., 3., 4.],\n",
       "       [5., 6., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with TFVariables\n",
    "tf.constant([[2,3,4], [5,6,7]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[2., 3., 4.],\n",
       "       [5., 6., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variable and the constant looks much the same\n",
    "tf.Variable(tf.constant([[2,3,4], [5,6,7]], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 3) dtype=float32, numpy=array([[2., 3., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The different between a tensor and a variable is that the variable can be reassigned\n",
    "new_variable = tf.Variable(tf.constant([[2,3,4]], dtype='float32'))\n",
    "new_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadamar Product/Pairwise calculation: \n",
      "[[ 4 10 18]\n",
      " [28 40 54]]\n"
     ]
    }
   ],
   "source": [
    "# Tell TensorFlow which device to use\n",
    "with tf.device('CPU:0'):\n",
    "    var_1 = tf.Variable([[1,2,3], [4,5,6]])\n",
    "    var_2 = tf.Variable([[4,5,6], [7,8,9]])\n",
    "\n",
    "    # perform an element wise calculation or get the Hadamar product\n",
    "    print(f'Hadamard Product/Pairwise calculation: \\n{ var_1 * var_2 }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 4.,  8., 14.], dtype=float32)>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing math operation with Variables\n",
    "x_data = tf.constant([2., 3., 4.], dtype=tf.float32)\n",
    "weights = tf.Variable([1., 2., 3.], dtype=tf.float32)\n",
    "bias = tf.Variable([2.0])\n",
    "\n",
    "# Make a prediction via element wise / Hadamard product\n",
    "y_hat = (x_data * weights) + bias\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3.], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a variable x\n",
    "x = tf.Variable([3, 3.], dtype=tf.float32)\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9., 9.], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square x and store it in y\n",
    "y = x**2\n",
    "y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9., 9.], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or alternatively\n",
    "tf.math.square(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9. 9.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# What is the derivative of y with respect to X\n",
    "# Starting with gradient tape\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 6.], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the gradient tape to find the derivative of y with respect to x\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.layers.core.dense.Dense at 0x151487d8c70>,\n",
       " <tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[1., 2., 3.]], dtype=float32)>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From a different perspective, using a ML model\n",
    "tf.keras.utils.set_random_seed(10)\n",
    "layer = tf.keras.layers.Dense(units=2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]], dtype=tf.float32)\n",
    "layer, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[2.893621, 4.519438]], dtype=float32)>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look to see what the output of the neurons are\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted: [[2.893621 4.519438]]\n",
      "Model loss: 14.399179458618164\n"
     ]
    }
   ],
   "source": [
    "# Leveraging the GradientTape()\n",
    "with tf.GradientTape() as tape:\n",
    "    # Do the forward pass\n",
    "    y_hat = layer(x)\n",
    "    print(f'Model predicted: {y_hat}')\n",
    "    # Compute the loss\n",
    "    loss = tf.reduce_mean(y_hat**2)\n",
    "    print(f'Model loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[ 2.893621,  4.519438],\n",
       "        [ 5.787242,  9.038876],\n",
       "        [ 8.680862, 13.558313]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2.893621, 4.519438], dtype=float32)>]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the gradient with respect to the training variables\n",
    "gradient = tape.gradient(loss, layer.trainable_variables)\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_22/kernel:0 (3, 2)\n",
      "dense_22/bias:0 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get information on the weights and biases\n",
    "for var, g in zip(layer.trainable_variables, gradient):\n",
    "    print(var.name, g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "145734096ae1081724030cf25431718f2a6f59d32c1cbcdd3e9f0255fad3b9b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
